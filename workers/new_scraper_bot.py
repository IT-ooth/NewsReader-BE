import threading
import time
from sqlmodel import Session
from db import services, engine, init_db
from scrapers import BoanNewsScraper, GeekNewsScraper, S2WScraper

def scraper_thread(scraper):
    """ê° ìŠ¤í¬ë˜í¼ë³„ ë…ë¦½ ë£¨í”„"""
    while True:
        print(f"ğŸ“¡ {scraper.source} ìŠ¤í¬ë˜í•‘ ì‹œì‘...")
        with Session(engine) as session:
            try:
                scraped_items = scraper.collect(session)
                for item in scraped_items:
                    if not services.get_article_by_url(session, item.url):
                        services.save_article(session, item)
                        print(f"ğŸ“¥ ìƒˆ ê¸°ì‚¬ ì €ì¥: {item.title[:20]}...")
                session.commit()
            except Exception as e:
                print(f"âŒ {scraper.source} ì—ëŸ¬: {e}")
        
        time.sleep(scraper.period)

def run_scraper_bot():
    init_db()
    scrapers = [
        BoanNewsScraper('http://www.boannews.com/media/news_rss.xml?skind=1', 10800),
        GeekNewsScraper('https://news.hada.io/rss/news', 10800),
        S2WScraper('https://medium.com/feed/s2wblog', 86400) # S2WëŠ” í•˜ë£¨ ì£¼ê¸°
    ]
    
    for s in scrapers:
        threading.Thread(target=scraper_thread, args=(s,), daemon=True).start()
    
    print("ğŸš€ Scraper Bot ê°€ë™ ì¤‘...")
    while True: time.sleep(1)

if __name__ == "__main__":
    run_scraper_bot()